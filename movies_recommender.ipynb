{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At first there is some analysis and then implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data and preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data into dataframes\n",
    "\n",
    "data_folder = \"data\"\n",
    "\n",
    "movies = pd.read_csv(os.path.join(data_folder, \"movies.csv\")).drop(\"genres\", axis=1) # We do not need genres right at the start\n",
    "ratings = pd.read_csv(os.path.join(data_folder, \"ratings.csv\")).drop(\"timestamp\", axis=1) # timestap not needed too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a mapping from film_id to film name\n",
    "movies_mapping = {}\n",
    "for index, row in movies.iterrows():\n",
    "    movies_mapping[row.movieId] = row.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leaving only reviews that are either positive or negative and then binarizing them\n",
    "mask_with_useful_ratings = (ratings.rating >=4)  | (ratings.rating <= 2)\n",
    "\n",
    "#I do not perform splitting here as Ill need later this frame for genres.\n",
    "useful_ratings = ratings.loc[mask_with_useful_ratings,:].copy() #Withouth this Pandas was raising a warning about performing operation on slices. \n",
    "\n",
    "useful_ratings[\"rating\"] = useful_ratings.rating.apply(lambda x: 1 if x >= 4 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting number of users and their Id's, moreover I was wondering if I should use test set.\n",
    "#At the beginning I've tried to use test set but then I didn't know how to evaluate these rules based on the test set so I give up\n",
    "#While creating and association rules\n",
    "users = useful_ratings.userId.unique()\n",
    "num_of_users = users.size\n",
    "\n",
    "#size_of_test_set = 0.01\n",
    "#users_test, users_train = users[:int(num_of_users*size_of_test_set)], users[int(num_of_users*size_of_test_set):]\n",
    "users_train = users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating 2 separate dataframes one for positive rating and second for negative\n",
    "useful_ratings_positive = useful_ratings[useful_ratings.rating == 1]\n",
    "useful_ratings_negative = useful_ratings[useful_ratings.rating == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one user is our service seems to be a one transaction\n",
    "#This table is in 1NF and we must instead create a list of reviewed films by every user\n",
    "positive_transactions = [\n",
    "    list(useful_ratings_positive[useful_ratings_positive.userId == x].movieId)\n",
    "    for x in users_train\n",
    "]\n",
    "\n",
    "negative_transactions = [\n",
    "    list(useful_ratings_negative[useful_ratings_negative.userId == x].movieId)\n",
    "    for x in users_train\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspecting the positive transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth # use fpgrowth\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit_transform(positive_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(te_array, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671, 6170)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # So we have only 671 users in the database, and they've commented positively on 6k films, whereas we have 9k in our base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count how many films were reviewed how many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6170.000000\n",
       "mean        8.357861\n",
       "std        18.314944\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         7.000000\n",
       "max       274.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum().describe() # To include half of a films we would need to set support equal to 2 reviews! Very small number\n",
    "#Also we have a few films that were reviewed so many times. Maybe these are classic watched by everybody?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of amount of reviews')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(df.sum(), 50)\n",
    "plt.xlabel(\"Number of reviews\")\n",
    "plt.ylabel(\"Number of films\")\n",
    "plt.title(\"Distribution of amount of reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that most of the films are rather rarely reviewed. Most of them appears only few times, so support for itemsets containing these films will be very small. As a result these films won't be included in any association rule. What to do if user starts watching from these films, what to recommend then?\n",
    "\n",
    "We have 671 movies, so if we set support to 5% then movie needs to be at least 34 times reviewed so we will reject most of the movies\n",
    "\n",
    "Moreover movies that were watched many times, may be classics and these are being shown in everyone's basket. So they will\n",
    "create very big itemsets that do not bring anything new, as everyone likes classic films\n",
    "\n",
    "So maybe different approach would work better. I think that we are not very interested in very long associations rules, but rather shorter ones\n",
    "So that based on 2/3 lastly seen movies we can with high precission recommend next 1/2 to watch. `So maybe a good idea would be to restrict the length of itemsets`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's see how many reviews one users give"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     671.000000\n",
       "mean       76.852459\n",
       "std       106.181753\n",
       "min         1.000000\n",
       "25%        20.000000\n",
       "50%        41.000000\n",
       "75%        88.500000\n",
       "max      1115.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum(axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(df.sum(axis=1), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again trend is very similar. Most of the users do not give that many reviews. However, we have some outliers who gave more than 1k positive reviews. Are these critics? Or these are bots that comment everything positively? Should we do anything with them? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating frequent datasets\n",
    "\n",
    "Let's try at first typical setting with min support 5% which corresponds to a films being watched 34 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = fpgrowth(df, min_support=0.05, use_colnames=True) #fpgrowth is much faster than apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053651</td>\n",
       "      <td>(1172)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.375559</td>\n",
       "      <td>(296)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.307004</td>\n",
       "      <td>(527)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.257824</td>\n",
       "      <td>(50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.253353</td>\n",
       "      <td>(589)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>0.052161</td>\n",
       "      <td>(296, 46578)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>0.052161</td>\n",
       "      <td>(8360, 4306)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>0.062593</td>\n",
       "      <td>(587, 356)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>0.050671</td>\n",
       "      <td>(260, 1517)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>0.058122</td>\n",
       "      <td>(539, 356)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        support      itemsets\n",
       "0      0.053651        (1172)\n",
       "1      0.375559         (296)\n",
       "2      0.307004         (527)\n",
       "3      0.257824          (50)\n",
       "4      0.253353         (589)\n",
       "...         ...           ...\n",
       "17192  0.052161  (296, 46578)\n",
       "17193  0.052161  (8360, 4306)\n",
       "17194  0.062593    (587, 356)\n",
       "17195  0.050671   (260, 1517)\n",
       "17196  0.058122    (539, 356)\n",
       "\n",
       "[17197 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_ratings_rules = association_rules(frequent_itemsets, metric='lift', min_threshold=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's calculate how many films the rules covered, So let's just check how many distinct antecedents we have\n",
    "all_films = set()\n",
    "for index, films in positive_ratings_rules.antecedents.iteritems():\n",
    "    all_films = all_films.union(films)\n",
    "\n",
    "len(all_films) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This make no sense to use only 100 films out of 6k possible! So definitelly we need to change the approach and maybe try to restrict length of frequent itemsets.\n",
    "\n",
    "Let's try some extreme setting to see if we are able to cover more films using smaller support but restricting max length of the rule\n",
    "\n",
    "`with min_support set to 0.01 it runs about 7 minutes! you can decrease it. I was curious what it would give.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = fpgrowth(df, min_support=0.01, use_colnames=True, max_len=3) \n",
    "#Basically difference between sizes of frequent itemsets even if we change support by a little here is very big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2283883, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets.shape # So we have MUCH more frequent itemsets (probably most of them is thrash), but do we even cover more films?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_ratings_rules = association_rules(frequent_itemsets, metric='lift', min_threshold=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1413"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's calculate how many films the rules covered\n",
    "all_films = set()\n",
    "for index, films in positive_ratings_rules.antecedents.iteritems():\n",
    "    all_films = all_films.union(films)\n",
    "\n",
    "len(all_films) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not that many films. Only 1413 from 6k in corpus (9k in entire database). Probability that first watched film won't be from that pool is about $\\frac{1413}{6000} \\approx 80\\%$, that 2 films are not from that pool about 50% `(I assumed independence and just muliply probabilities in reality this probably differs.)` so it is very likely that even after watching a few films we will still be forced to show some random recomendations.\n",
    "\n",
    "Moreover some rules may still be conjunctions $A \\wedge B -> C$ and we may not have just $A -> C$ in the base (proofed this to myself by simple van diagram). So what if user watched just A? We can make poor assumptions that $A \\wedge B ->C <=> A -> C \\wedge B -> C$ But this in some cases may give strange results. As an example If someone liked romance and horror then for sure they will like some romance with horror elements but if they just liked romance it make no sense to assume they will like merge of them\n",
    "\n",
    "Another thing would be to assume symmetricity and one step transitivity of these rules (This is may be closer to the true in case of films than previous assumption). So if user liked movie A, but we do not have any rule A -> X, then we check if we have anything B -> A. Then, we could assume that all rules B -> X, where X is random film hold also for A. So then we can also use movies that are only consequents. But how much more we have then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1413"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Additionally add consequents to all possible films\n",
    "for index, films in positive_ratings_rules.consequents.iteritems():\n",
    "    all_films = all_films.union(films)\n",
    "len(all_films)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Didn't expected that we won't gain anything... So maybe this symmetricity holds with such a small support?\n",
    "\n",
    "Next idea I have is to incorporate Multilevel Association Rules and use information about film genres, which I've previously dropped. If rules incorporating genres will be trivial and not helping at all, then eventually if we do not have information in rules, we can use correlation between genres or just recommend random movie from the same genre as previosuly watched one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_genre = pd.read_csv(os.path.join(data_folder, \"movies.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a mapping from film_id to [film_name, film_genres] \n",
    "movies_mapping_genre = {}\n",
    "all_genres = set()\n",
    "for index, row in movies_genre.iterrows():\n",
    "    movies_mapping_genre[row.movieId] = []\n",
    "    movies_mapping_genre[row.movieId].append(row.title)\n",
    "    movie_genres = row.genres.split(\"|\")\n",
    "    all_genres = all_genres.union(set(movie_genres))\n",
    "    movies_mapping_genre[row.movieId].append(movie_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Documentary', 'Adventure', 'Crime', 'Fantasy', 'Animation', 'Drama', 'Mystery', 'Children', 'Western', 'Horror', 'Romance', 'War', 'IMAX', 'Action', 'Thriller', 'Musical', '(no genres listed)', 'Comedy', 'Film-Noir', 'Sci-Fi'}\n"
     ]
    }
   ],
   "source": [
    "print(all_genres)  # no genres listed.. We should do something with this probably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and movies withouth a genre are reviewed, so not sure what should I do here with that category\n",
    "len(set(ratings.movieId).intersection(set(movies_genre[movies_genre[\"genres\"]==\"(no genres listed)\"].movieId))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count which genres user like. I assume a user like genre if balance liked_movies_from_genre - not_liked_movies_from_genre is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "all_genres_list_sorted = sorted(list(all_genres)) # I want this mapping to always be the same, with set this may not be the case\n",
    "mapping_genre_to_numbers = {v:k for k,v in zip(range(len(all_genres)), all_genres_list_sorted)}\n",
    "\n",
    "# mapping_genre_to_numbers_shifted_by_films = {v:k for k,v in zip(range(len(all_genres)), all_genres_list_sorted)}  \n",
    "num_of_genres = len(all_genres) \n",
    "\n",
    "user_genres = defaultdict(lambda : [0] * num_of_genres)\n",
    "\n",
    "#maybe this could be vectorized but not sure how to do it\n",
    "for index, row in useful_ratings.iterrows():\n",
    "    userId, movieId, rating = row\n",
    "    for genre in movies_mapping_genre[movieId][1]:\n",
    "        user_genres[userId][mapping_genre_to_numbers[genre]] += rating #ratings now are either 1 or -1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>69</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     (no genres listed)  Action  Adventure  Animation  Children  Comedy  \\\n",
       "1                     0      -1         -5         -2        -1      -3   \n",
       "2                     0       4          7          3         3       3   \n",
       "3                     0       5          2         -1        -1       8   \n",
       "4                     0      47         51         22        37      69   \n",
       "5                     0      10         12          6         9      39   \n",
       "..                  ...     ...        ...        ...       ...     ...   \n",
       "667                   0       4          4          4         4      14   \n",
       "668                   0       1          0          0         0       2   \n",
       "669                   0       4          3          0         0       6   \n",
       "670                   0       2          2          1         2       3   \n",
       "671                   0      15         21          9        12      31   \n",
       "\n",
       "     Crime  Documentary  Drama  Fantasy  Film-Noir  Horror  IMAX  Musical  \\\n",
       "1        0            0     -2       -3          0       0     0        0   \n",
       "2        5            0     19        2          0       2     1        2   \n",
       "3        4            1     16        0          0       1    -1       -1   \n",
       "4       25            1     48       32          1      10     1       23   \n",
       "5        4            1     24        8          0       2     4        8   \n",
       "..     ...          ...    ...      ...        ...     ...   ...      ...   \n",
       "667      5            0     22        4          0       0     1        2   \n",
       "668      6            0     10        1          0       1     0        0   \n",
       "669      2            0      4        0          1      -3     0        0   \n",
       "670      4            0      9        1         -2       1     0        0   \n",
       "671     15            3     33       14          0       2     1        7   \n",
       "\n",
       "     Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "1          0        0      -1        -1   -1        0  \n",
       "2          4        8       3         7    3        2  \n",
       "3          1        4       0         4    5        1  \n",
       "4          6       26      32        29    4        0  \n",
       "5          0       30       5         5    3        0  \n",
       "..       ...      ...     ...       ...  ...      ...  \n",
       "667        1        6       3         7    4        0  \n",
       "668        0        1       0         3    2        0  \n",
       "669        1        1      -2         0    0        1  \n",
       "670        1        3       3         5    2       -1  \n",
       "671        4       14       8        17    5        3  \n",
       "\n",
       "[671 rows x 20 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_sentiment = pd.DataFrame(user_genres).transpose()\n",
    "genres_sentiment.columns = all_genres_list_sorted\n",
    "genres_sentiment # We get new cool dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_sentiment_class = genres_sentiment.apply(lambda x: np.sign(x)) #now if anyone likes a genre it get 1 if don't it get -1 if 0 then we do not care"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging genres information with film information was not the best idea as then we then have just too much trivial frequent sets and algorithm works veeery slow. Im just leaving the cell in which I've merged these two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_transactions_film_and_genre = []\n",
    "for userId in users_train:\n",
    "    liked_movies = list(useful_ratings_positive[useful_ratings_positive.userId == userId].movieId + num_of_genres)  # not to have ovelapping genre indices with film indices\n",
    "    #so first 19 indices are devoted for genres\n",
    "    liked_genres = np.argwhere((genres_sentiment_class.loc[userId] == 1).to_numpy())\n",
    "    positive_transactions_film_and_genre.append(list(liked_genres.flatten()) + liked_movies )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so maybe we can just try to learn which genre works well with one another and if user hasn't watched enough movies recommend based on the genre information. And it seems that this baskets have completely different characteristic. As we have only 17 elements in it to have reasonable outcomes min_support should be much higher. However the lift values should be rather small to get any rules not filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_transactions_genre = []\n",
    "for userId in users_train:\n",
    "    liked_genres = np.argwhere((genres_sentiment_class.loc[userId] == 1).to_numpy())\n",
    "    positive_transactions_genre.append(list(liked_genres.flatten()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_array = te.fit_transform(positive_transactions_genre)\n",
    "\n",
    "df = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "frequent_itemsets = fpgrowth(df, min_support=0.6, use_colnames=True, max_len=4) #in that case we have small amount of items and they probably are quite often\n",
    "#So support should be high, I also think that constraining size of the frequent itemset is a good idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.940387</td>\n",
       "      <td>(8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.891207</td>\n",
       "      <td>(6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.874814</td>\n",
       "      <td>(17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.862891</td>\n",
       "      <td>(15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.853949</td>\n",
       "      <td>(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.600596</td>\n",
       "      <td>(9, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0.605067</td>\n",
       "      <td>(8, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>0.605067</td>\n",
       "      <td>(8, 3, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.602086</td>\n",
       "      <td>(8, 3, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0.602086</td>\n",
       "      <td>(8, 3, 15)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>555 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      support    itemsets\n",
       "0    0.940387         (8)\n",
       "1    0.891207         (6)\n",
       "2    0.874814        (17)\n",
       "3    0.862891        (15)\n",
       "4    0.853949         (5)\n",
       "..        ...         ...\n",
       "550  0.600596      (9, 3)\n",
       "551  0.605067   (8, 2, 3)\n",
       "552  0.605067   (8, 3, 6)\n",
       "553  0.602086   (8, 3, 5)\n",
       "554  0.602086  (8, 3, 15)\n",
       "\n",
       "[555 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_genres_rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1.2) \n",
    "# generally lift is quite small in that case to get anything passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 2, 17)</td>\n",
       "      <td>(16)</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.760060</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.201279</td>\n",
       "      <td>0.115365</td>\n",
       "      <td>2.759314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(16, 2)</td>\n",
       "      <td>(1, 17)</td>\n",
       "      <td>0.719821</td>\n",
       "      <td>0.794337</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.204177</td>\n",
       "      <td>0.116744</td>\n",
       "      <td>4.730253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(16, 17)</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.730253</td>\n",
       "      <td>0.773472</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1.218993</td>\n",
       "      <td>0.123694</td>\n",
       "      <td>3.964232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>(16, 17)</td>\n",
       "      <td>0.773472</td>\n",
       "      <td>0.730253</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.890173</td>\n",
       "      <td>1.218993</td>\n",
       "      <td>0.123694</td>\n",
       "      <td>2.456114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 17)</td>\n",
       "      <td>(16, 2)</td>\n",
       "      <td>0.794337</td>\n",
       "      <td>0.719821</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.866792</td>\n",
       "      <td>1.204177</td>\n",
       "      <td>0.116744</td>\n",
       "      <td>2.103314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>(4)</td>\n",
       "      <td>(8, 9, 5)</td>\n",
       "      <td>0.678092</td>\n",
       "      <td>0.719821</td>\n",
       "      <td>0.603577</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>1.236571</td>\n",
       "      <td>0.115471</td>\n",
       "      <td>2.549627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>(3)</td>\n",
       "      <td>(4)</td>\n",
       "      <td>0.651267</td>\n",
       "      <td>0.678092</td>\n",
       "      <td>0.603577</td>\n",
       "      <td>0.926773</td>\n",
       "      <td>1.366736</td>\n",
       "      <td>0.161958</td>\n",
       "      <td>4.396051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>(4)</td>\n",
       "      <td>(3)</td>\n",
       "      <td>0.678092</td>\n",
       "      <td>0.651267</td>\n",
       "      <td>0.603577</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>1.366736</td>\n",
       "      <td>0.161958</td>\n",
       "      <td>3.173472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>(9)</td>\n",
       "      <td>(3)</td>\n",
       "      <td>0.758569</td>\n",
       "      <td>0.651267</td>\n",
       "      <td>0.600596</td>\n",
       "      <td>0.791749</td>\n",
       "      <td>1.215705</td>\n",
       "      <td>0.106565</td>\n",
       "      <td>1.674578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>(3)</td>\n",
       "      <td>(9)</td>\n",
       "      <td>0.651267</td>\n",
       "      <td>0.758569</td>\n",
       "      <td>0.600596</td>\n",
       "      <td>0.922197</td>\n",
       "      <td>1.215705</td>\n",
       "      <td>0.106565</td>\n",
       "      <td>3.103095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    antecedents consequents  antecedent support  consequent support   support  \\\n",
       "0    (1, 2, 17)        (16)            0.754098            0.760060  0.688525   \n",
       "1       (16, 2)     (1, 17)            0.719821            0.794337  0.688525   \n",
       "2      (16, 17)      (1, 2)            0.730253            0.773472  0.688525   \n",
       "3        (1, 2)    (16, 17)            0.773472            0.730253  0.688525   \n",
       "4       (1, 17)     (16, 2)            0.794337            0.719821  0.688525   \n",
       "..          ...         ...                 ...                 ...       ...   \n",
       "147         (4)   (8, 9, 5)            0.678092            0.719821  0.603577   \n",
       "148         (3)         (4)            0.651267            0.678092  0.603577   \n",
       "149         (4)         (3)            0.678092            0.651267  0.603577   \n",
       "150         (9)         (3)            0.758569            0.651267  0.600596   \n",
       "151         (3)         (9)            0.651267            0.758569  0.600596   \n",
       "\n",
       "     confidence      lift  leverage  conviction  \n",
       "0      0.913043  1.201279  0.115365    2.759314  \n",
       "1      0.956522  1.204177  0.116744    4.730253  \n",
       "2      0.942857  1.218993  0.123694    3.964232  \n",
       "3      0.890173  1.218993  0.123694    2.456114  \n",
       "4      0.866792  1.204177  0.116744    2.103314  \n",
       "..          ...       ...       ...         ...  \n",
       "147    0.890110  1.236571  0.115471    2.549627  \n",
       "148    0.926773  1.366736  0.161958    4.396051  \n",
       "149    0.890110  1.366736  0.161958    3.173472  \n",
       "150    0.791749  1.215705  0.106565    1.674578  \n",
       "151    0.922197  1.215705  0.106565    3.103095  \n",
       "\n",
       "[152 rows x 9 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_genres_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check how many rules consider just one genre as antecedent. It is only 4 so not good..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#SO with that setting only genre number 3 is included\n",
    "single_antecedent_genres = set()\n",
    "\n",
    "for i in positive_genres_rules.antecedents.iteritems():\n",
    "    if len(i[1]) == 1:\n",
    "        single_antecedent_genres = single_antecedent_genres.union(set(i[1]))\n",
    "\n",
    "print(len(single_antecedent_genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that we could look for associations rules iteratively at the very end. At first try to create very short rules (only A->B) but with low support not to miss the rarest film rules. And then in each iteration increase minsupport and allowed rule length. After that we could somehow filter these rules further for all the films selecting just these with the biggest support and lift. With this approach we probably would be able to cover a lot of films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another idea is to somehow see if there is some kind of correlation between genres that we can observe. we can treat every column as a one random variable. I think that we are mostly interested in that binary random variable. If we take counts into account, the variance is much bigger. In general our goal is not to predict how many films someone will watch but just if they will like it.\n",
    "\n",
    "It is quite interesting that there are some genres with high positive correlation with another, so if we like Action probably we will like Adventure too. However, negative correlation between genres never occured this is probably due to smaller amount of negative reviews at all. So If we like Adventure it does not determine that we won't like documentary, correlation(adventure, documentary) is rather small so then it probably depends on how good particular film is and not on genre itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(no genres listed)</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.072428</td>\n",
       "      <td>0.054559</td>\n",
       "      <td>0.060091</td>\n",
       "      <td>0.041671</td>\n",
       "      <td>0.070159</td>\n",
       "      <td>0.074499</td>\n",
       "      <td>0.105530</td>\n",
       "      <td>0.022034</td>\n",
       "      <td>0.079907</td>\n",
       "      <td>0.057415</td>\n",
       "      <td>0.083712</td>\n",
       "      <td>0.116656</td>\n",
       "      <td>0.069104</td>\n",
       "      <td>0.084376</td>\n",
       "      <td>0.072541</td>\n",
       "      <td>0.032693</td>\n",
       "      <td>0.072219</td>\n",
       "      <td>0.042681</td>\n",
       "      <td>0.068888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>0.072428</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.620187</td>\n",
       "      <td>0.301987</td>\n",
       "      <td>0.333484</td>\n",
       "      <td>0.499832</td>\n",
       "      <td>0.421918</td>\n",
       "      <td>0.077340</td>\n",
       "      <td>0.396255</td>\n",
       "      <td>0.386283</td>\n",
       "      <td>0.065782</td>\n",
       "      <td>0.310594</td>\n",
       "      <td>0.297404</td>\n",
       "      <td>0.184473</td>\n",
       "      <td>0.420163</td>\n",
       "      <td>0.475434</td>\n",
       "      <td>0.588742</td>\n",
       "      <td>0.607969</td>\n",
       "      <td>0.375418</td>\n",
       "      <td>0.273856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>0.054559</td>\n",
       "      <td>0.620187</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.444931</td>\n",
       "      <td>0.536862</td>\n",
       "      <td>0.567869</td>\n",
       "      <td>0.358604</td>\n",
       "      <td>0.073244</td>\n",
       "      <td>0.491780</td>\n",
       "      <td>0.579899</td>\n",
       "      <td>0.121610</td>\n",
       "      <td>0.251667</td>\n",
       "      <td>0.392071</td>\n",
       "      <td>0.322965</td>\n",
       "      <td>0.370934</td>\n",
       "      <td>0.561921</td>\n",
       "      <td>0.566374</td>\n",
       "      <td>0.546369</td>\n",
       "      <td>0.348233</td>\n",
       "      <td>0.295900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>0.060091</td>\n",
       "      <td>0.301987</td>\n",
       "      <td>0.444931</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.746318</td>\n",
       "      <td>0.400014</td>\n",
       "      <td>0.267921</td>\n",
       "      <td>0.135440</td>\n",
       "      <td>0.339384</td>\n",
       "      <td>0.524819</td>\n",
       "      <td>0.099279</td>\n",
       "      <td>0.207543</td>\n",
       "      <td>0.384757</td>\n",
       "      <td>0.537097</td>\n",
       "      <td>0.268271</td>\n",
       "      <td>0.349184</td>\n",
       "      <td>0.323964</td>\n",
       "      <td>0.278144</td>\n",
       "      <td>0.291722</td>\n",
       "      <td>0.257724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Children</th>\n",
       "      <td>0.041671</td>\n",
       "      <td>0.333484</td>\n",
       "      <td>0.536862</td>\n",
       "      <td>0.746318</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.463204</td>\n",
       "      <td>0.243853</td>\n",
       "      <td>0.130146</td>\n",
       "      <td>0.335374</td>\n",
       "      <td>0.606182</td>\n",
       "      <td>0.087675</td>\n",
       "      <td>0.201670</td>\n",
       "      <td>0.361771</td>\n",
       "      <td>0.509702</td>\n",
       "      <td>0.248060</td>\n",
       "      <td>0.394670</td>\n",
       "      <td>0.360690</td>\n",
       "      <td>0.308931</td>\n",
       "      <td>0.293932</td>\n",
       "      <td>0.260711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>0.070159</td>\n",
       "      <td>0.499832</td>\n",
       "      <td>0.567869</td>\n",
       "      <td>0.400014</td>\n",
       "      <td>0.463204</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.443361</td>\n",
       "      <td>0.121408</td>\n",
       "      <td>0.456537</td>\n",
       "      <td>0.577836</td>\n",
       "      <td>0.083885</td>\n",
       "      <td>0.311831</td>\n",
       "      <td>0.169237</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.377169</td>\n",
       "      <td>0.637221</td>\n",
       "      <td>0.430874</td>\n",
       "      <td>0.505719</td>\n",
       "      <td>0.315629</td>\n",
       "      <td>0.314351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>0.074499</td>\n",
       "      <td>0.421918</td>\n",
       "      <td>0.358604</td>\n",
       "      <td>0.267921</td>\n",
       "      <td>0.243853</td>\n",
       "      <td>0.443361</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.195110</td>\n",
       "      <td>0.515535</td>\n",
       "      <td>0.388604</td>\n",
       "      <td>0.144717</td>\n",
       "      <td>0.317717</td>\n",
       "      <td>0.220753</td>\n",
       "      <td>0.213467</td>\n",
       "      <td>0.466403</td>\n",
       "      <td>0.346363</td>\n",
       "      <td>0.388698</td>\n",
       "      <td>0.529792</td>\n",
       "      <td>0.294340</td>\n",
       "      <td>0.225280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>0.105530</td>\n",
       "      <td>0.077340</td>\n",
       "      <td>0.073244</td>\n",
       "      <td>0.135440</td>\n",
       "      <td>0.130146</td>\n",
       "      <td>0.121408</td>\n",
       "      <td>0.195110</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.167631</td>\n",
       "      <td>0.130072</td>\n",
       "      <td>0.348751</td>\n",
       "      <td>0.103488</td>\n",
       "      <td>0.132187</td>\n",
       "      <td>0.198055</td>\n",
       "      <td>0.165501</td>\n",
       "      <td>0.147262</td>\n",
       "      <td>0.036460</td>\n",
       "      <td>0.115036</td>\n",
       "      <td>0.178522</td>\n",
       "      <td>0.165732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>0.022034</td>\n",
       "      <td>0.396255</td>\n",
       "      <td>0.491780</td>\n",
       "      <td>0.339384</td>\n",
       "      <td>0.335374</td>\n",
       "      <td>0.456537</td>\n",
       "      <td>0.515535</td>\n",
       "      <td>0.167631</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.369551</td>\n",
       "      <td>0.101185</td>\n",
       "      <td>0.242217</td>\n",
       "      <td>0.202953</td>\n",
       "      <td>0.321355</td>\n",
       "      <td>0.391973</td>\n",
       "      <td>0.512735</td>\n",
       "      <td>0.326998</td>\n",
       "      <td>0.520476</td>\n",
       "      <td>0.434633</td>\n",
       "      <td>0.246398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>0.079907</td>\n",
       "      <td>0.386283</td>\n",
       "      <td>0.579899</td>\n",
       "      <td>0.524819</td>\n",
       "      <td>0.606182</td>\n",
       "      <td>0.577836</td>\n",
       "      <td>0.388604</td>\n",
       "      <td>0.130072</td>\n",
       "      <td>0.369551</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.151663</td>\n",
       "      <td>0.285250</td>\n",
       "      <td>0.326138</td>\n",
       "      <td>0.410207</td>\n",
       "      <td>0.345749</td>\n",
       "      <td>0.487521</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.373021</td>\n",
       "      <td>0.260921</td>\n",
       "      <td>0.290930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Film-Noir</th>\n",
       "      <td>0.057415</td>\n",
       "      <td>0.065782</td>\n",
       "      <td>0.121610</td>\n",
       "      <td>0.099279</td>\n",
       "      <td>0.087675</td>\n",
       "      <td>0.083885</td>\n",
       "      <td>0.144717</td>\n",
       "      <td>0.348751</td>\n",
       "      <td>0.101185</td>\n",
       "      <td>0.151663</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.130692</td>\n",
       "      <td>0.018552</td>\n",
       "      <td>0.153006</td>\n",
       "      <td>0.240208</td>\n",
       "      <td>0.069001</td>\n",
       "      <td>0.085663</td>\n",
       "      <td>0.094582</td>\n",
       "      <td>0.193204</td>\n",
       "      <td>0.216866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>0.083712</td>\n",
       "      <td>0.310594</td>\n",
       "      <td>0.251667</td>\n",
       "      <td>0.207543</td>\n",
       "      <td>0.201670</td>\n",
       "      <td>0.311831</td>\n",
       "      <td>0.317717</td>\n",
       "      <td>0.103488</td>\n",
       "      <td>0.242217</td>\n",
       "      <td>0.285250</td>\n",
       "      <td>0.130692</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.143493</td>\n",
       "      <td>0.170050</td>\n",
       "      <td>0.374570</td>\n",
       "      <td>0.285556</td>\n",
       "      <td>0.335646</td>\n",
       "      <td>0.419584</td>\n",
       "      <td>0.232018</td>\n",
       "      <td>0.150358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMAX</th>\n",
       "      <td>0.116656</td>\n",
       "      <td>0.297404</td>\n",
       "      <td>0.392071</td>\n",
       "      <td>0.384757</td>\n",
       "      <td>0.361771</td>\n",
       "      <td>0.169237</td>\n",
       "      <td>0.220753</td>\n",
       "      <td>0.132187</td>\n",
       "      <td>0.202953</td>\n",
       "      <td>0.326138</td>\n",
       "      <td>0.018552</td>\n",
       "      <td>0.143493</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.316537</td>\n",
       "      <td>0.182848</td>\n",
       "      <td>0.220014</td>\n",
       "      <td>0.258883</td>\n",
       "      <td>0.273935</td>\n",
       "      <td>0.223245</td>\n",
       "      <td>0.196501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Musical</th>\n",
       "      <td>0.069104</td>\n",
       "      <td>0.184473</td>\n",
       "      <td>0.322965</td>\n",
       "      <td>0.537097</td>\n",
       "      <td>0.509702</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.213467</td>\n",
       "      <td>0.198055</td>\n",
       "      <td>0.321355</td>\n",
       "      <td>0.410207</td>\n",
       "      <td>0.153006</td>\n",
       "      <td>0.170050</td>\n",
       "      <td>0.316537</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.205698</td>\n",
       "      <td>0.318643</td>\n",
       "      <td>0.169335</td>\n",
       "      <td>0.194430</td>\n",
       "      <td>0.252111</td>\n",
       "      <td>0.249686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>0.084376</td>\n",
       "      <td>0.420163</td>\n",
       "      <td>0.370934</td>\n",
       "      <td>0.268271</td>\n",
       "      <td>0.248060</td>\n",
       "      <td>0.377169</td>\n",
       "      <td>0.466403</td>\n",
       "      <td>0.165501</td>\n",
       "      <td>0.391973</td>\n",
       "      <td>0.345749</td>\n",
       "      <td>0.240208</td>\n",
       "      <td>0.374570</td>\n",
       "      <td>0.182848</td>\n",
       "      <td>0.205698</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.316610</td>\n",
       "      <td>0.369833</td>\n",
       "      <td>0.517156</td>\n",
       "      <td>0.330396</td>\n",
       "      <td>0.225008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>0.072541</td>\n",
       "      <td>0.475434</td>\n",
       "      <td>0.561921</td>\n",
       "      <td>0.349184</td>\n",
       "      <td>0.394670</td>\n",
       "      <td>0.637221</td>\n",
       "      <td>0.346363</td>\n",
       "      <td>0.147262</td>\n",
       "      <td>0.512735</td>\n",
       "      <td>0.487521</td>\n",
       "      <td>0.069001</td>\n",
       "      <td>0.285556</td>\n",
       "      <td>0.220014</td>\n",
       "      <td>0.318643</td>\n",
       "      <td>0.316610</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.394040</td>\n",
       "      <td>0.453176</td>\n",
       "      <td>0.360752</td>\n",
       "      <td>0.284363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sci-Fi</th>\n",
       "      <td>0.032693</td>\n",
       "      <td>0.588742</td>\n",
       "      <td>0.566374</td>\n",
       "      <td>0.323964</td>\n",
       "      <td>0.360690</td>\n",
       "      <td>0.430874</td>\n",
       "      <td>0.388698</td>\n",
       "      <td>0.036460</td>\n",
       "      <td>0.326998</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.085663</td>\n",
       "      <td>0.335646</td>\n",
       "      <td>0.258883</td>\n",
       "      <td>0.169335</td>\n",
       "      <td>0.369833</td>\n",
       "      <td>0.394040</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.521728</td>\n",
       "      <td>0.267912</td>\n",
       "      <td>0.250326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>0.072219</td>\n",
       "      <td>0.607969</td>\n",
       "      <td>0.546369</td>\n",
       "      <td>0.278144</td>\n",
       "      <td>0.308931</td>\n",
       "      <td>0.505719</td>\n",
       "      <td>0.529792</td>\n",
       "      <td>0.115036</td>\n",
       "      <td>0.520476</td>\n",
       "      <td>0.373021</td>\n",
       "      <td>0.094582</td>\n",
       "      <td>0.419584</td>\n",
       "      <td>0.273935</td>\n",
       "      <td>0.194430</td>\n",
       "      <td>0.517156</td>\n",
       "      <td>0.453176</td>\n",
       "      <td>0.521728</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.368807</td>\n",
       "      <td>0.262140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War</th>\n",
       "      <td>0.042681</td>\n",
       "      <td>0.375418</td>\n",
       "      <td>0.348233</td>\n",
       "      <td>0.291722</td>\n",
       "      <td>0.293932</td>\n",
       "      <td>0.315629</td>\n",
       "      <td>0.294340</td>\n",
       "      <td>0.178522</td>\n",
       "      <td>0.434633</td>\n",
       "      <td>0.260921</td>\n",
       "      <td>0.193204</td>\n",
       "      <td>0.232018</td>\n",
       "      <td>0.223245</td>\n",
       "      <td>0.252111</td>\n",
       "      <td>0.330396</td>\n",
       "      <td>0.360752</td>\n",
       "      <td>0.267912</td>\n",
       "      <td>0.368807</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.309179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western</th>\n",
       "      <td>0.068888</td>\n",
       "      <td>0.273856</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>0.257724</td>\n",
       "      <td>0.260711</td>\n",
       "      <td>0.314351</td>\n",
       "      <td>0.225280</td>\n",
       "      <td>0.165732</td>\n",
       "      <td>0.246398</td>\n",
       "      <td>0.290930</td>\n",
       "      <td>0.216866</td>\n",
       "      <td>0.150358</td>\n",
       "      <td>0.196501</td>\n",
       "      <td>0.249686</td>\n",
       "      <td>0.225008</td>\n",
       "      <td>0.284363</td>\n",
       "      <td>0.250326</td>\n",
       "      <td>0.262140</td>\n",
       "      <td>0.309179</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    (no genres listed)    Action  Adventure  Animation  \\\n",
       "(no genres listed)           -2.000000  0.072428   0.054559   0.060091   \n",
       "Action                        0.072428 -2.000000   0.620187   0.301987   \n",
       "Adventure                     0.054559  0.620187  -2.000000   0.444931   \n",
       "Animation                     0.060091  0.301987   0.444931  -2.000000   \n",
       "Children                      0.041671  0.333484   0.536862   0.746318   \n",
       "Comedy                        0.070159  0.499832   0.567869   0.400014   \n",
       "Crime                         0.074499  0.421918   0.358604   0.267921   \n",
       "Documentary                   0.105530  0.077340   0.073244   0.135440   \n",
       "Drama                         0.022034  0.396255   0.491780   0.339384   \n",
       "Fantasy                       0.079907  0.386283   0.579899   0.524819   \n",
       "Film-Noir                     0.057415  0.065782   0.121610   0.099279   \n",
       "Horror                        0.083712  0.310594   0.251667   0.207543   \n",
       "IMAX                          0.116656  0.297404   0.392071   0.384757   \n",
       "Musical                       0.069104  0.184473   0.322965   0.537097   \n",
       "Mystery                       0.084376  0.420163   0.370934   0.268271   \n",
       "Romance                       0.072541  0.475434   0.561921   0.349184   \n",
       "Sci-Fi                        0.032693  0.588742   0.566374   0.323964   \n",
       "Thriller                      0.072219  0.607969   0.546369   0.278144   \n",
       "War                           0.042681  0.375418   0.348233   0.291722   \n",
       "Western                       0.068888  0.273856   0.295900   0.257724   \n",
       "\n",
       "                    Children    Comedy     Crime  Documentary     Drama  \\\n",
       "(no genres listed)  0.041671  0.070159  0.074499     0.105530  0.022034   \n",
       "Action              0.333484  0.499832  0.421918     0.077340  0.396255   \n",
       "Adventure           0.536862  0.567869  0.358604     0.073244  0.491780   \n",
       "Animation           0.746318  0.400014  0.267921     0.135440  0.339384   \n",
       "Children           -2.000000  0.463204  0.243853     0.130146  0.335374   \n",
       "Comedy              0.463204 -2.000000  0.443361     0.121408  0.456537   \n",
       "Crime               0.243853  0.443361 -2.000000     0.195110  0.515535   \n",
       "Documentary         0.130146  0.121408  0.195110    -2.000000  0.167631   \n",
       "Drama               0.335374  0.456537  0.515535     0.167631 -2.000000   \n",
       "Fantasy             0.606182  0.577836  0.388604     0.130072  0.369551   \n",
       "Film-Noir           0.087675  0.083885  0.144717     0.348751  0.101185   \n",
       "Horror              0.201670  0.311831  0.317717     0.103488  0.242217   \n",
       "IMAX                0.361771  0.169237  0.220753     0.132187  0.202953   \n",
       "Musical             0.509702  0.372088  0.213467     0.198055  0.321355   \n",
       "Mystery             0.248060  0.377169  0.466403     0.165501  0.391973   \n",
       "Romance             0.394670  0.637221  0.346363     0.147262  0.512735   \n",
       "Sci-Fi              0.360690  0.430874  0.388698     0.036460  0.326998   \n",
       "Thriller            0.308931  0.505719  0.529792     0.115036  0.520476   \n",
       "War                 0.293932  0.315629  0.294340     0.178522  0.434633   \n",
       "Western             0.260711  0.314351  0.225280     0.165732  0.246398   \n",
       "\n",
       "                     Fantasy  Film-Noir    Horror      IMAX   Musical  \\\n",
       "(no genres listed)  0.079907   0.057415  0.083712  0.116656  0.069104   \n",
       "Action              0.386283   0.065782  0.310594  0.297404  0.184473   \n",
       "Adventure           0.579899   0.121610  0.251667  0.392071  0.322965   \n",
       "Animation           0.524819   0.099279  0.207543  0.384757  0.537097   \n",
       "Children            0.606182   0.087675  0.201670  0.361771  0.509702   \n",
       "Comedy              0.577836   0.083885  0.311831  0.169237  0.372088   \n",
       "Crime               0.388604   0.144717  0.317717  0.220753  0.213467   \n",
       "Documentary         0.130072   0.348751  0.103488  0.132187  0.198055   \n",
       "Drama               0.369551   0.101185  0.242217  0.202953  0.321355   \n",
       "Fantasy            -2.000000   0.151663  0.285250  0.326138  0.410207   \n",
       "Film-Noir           0.151663  -2.000000  0.130692  0.018552  0.153006   \n",
       "Horror              0.285250   0.130692 -2.000000  0.143493  0.170050   \n",
       "IMAX                0.326138   0.018552  0.143493 -2.000000  0.316537   \n",
       "Musical             0.410207   0.153006  0.170050  0.316537 -2.000000   \n",
       "Mystery             0.345749   0.240208  0.374570  0.182848  0.205698   \n",
       "Romance             0.487521   0.069001  0.285556  0.220014  0.318643   \n",
       "Sci-Fi              0.403993   0.085663  0.335646  0.258883  0.169335   \n",
       "Thriller            0.373021   0.094582  0.419584  0.273935  0.194430   \n",
       "War                 0.260921   0.193204  0.232018  0.223245  0.252111   \n",
       "Western             0.290930   0.216866  0.150358  0.196501  0.249686   \n",
       "\n",
       "                     Mystery   Romance    Sci-Fi  Thriller       War   Western  \n",
       "(no genres listed)  0.084376  0.072541  0.032693  0.072219  0.042681  0.068888  \n",
       "Action              0.420163  0.475434  0.588742  0.607969  0.375418  0.273856  \n",
       "Adventure           0.370934  0.561921  0.566374  0.546369  0.348233  0.295900  \n",
       "Animation           0.268271  0.349184  0.323964  0.278144  0.291722  0.257724  \n",
       "Children            0.248060  0.394670  0.360690  0.308931  0.293932  0.260711  \n",
       "Comedy              0.377169  0.637221  0.430874  0.505719  0.315629  0.314351  \n",
       "Crime               0.466403  0.346363  0.388698  0.529792  0.294340  0.225280  \n",
       "Documentary         0.165501  0.147262  0.036460  0.115036  0.178522  0.165732  \n",
       "Drama               0.391973  0.512735  0.326998  0.520476  0.434633  0.246398  \n",
       "Fantasy             0.345749  0.487521  0.403993  0.373021  0.260921  0.290930  \n",
       "Film-Noir           0.240208  0.069001  0.085663  0.094582  0.193204  0.216866  \n",
       "Horror              0.374570  0.285556  0.335646  0.419584  0.232018  0.150358  \n",
       "IMAX                0.182848  0.220014  0.258883  0.273935  0.223245  0.196501  \n",
       "Musical             0.205698  0.318643  0.169335  0.194430  0.252111  0.249686  \n",
       "Mystery            -2.000000  0.316610  0.369833  0.517156  0.330396  0.225008  \n",
       "Romance             0.316610 -2.000000  0.394040  0.453176  0.360752  0.284363  \n",
       "Sci-Fi              0.369833  0.394040 -2.000000  0.521728  0.267912  0.250326  \n",
       "Thriller            0.517156  0.453176  0.521728 -2.000000  0.368807  0.262140  \n",
       "War                 0.330396  0.360752  0.267912  0.368807 -2.000000  0.309179  \n",
       "Western             0.225008  0.284363  0.250326  0.262140  0.309179 -2.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_genres = len(genres_sentiment_class.columns)\n",
    "genres_sentiment_correlation = genres_sentiment_class.corr()\n",
    "genres_sentiment_correlation.values[np.arange(num_of_genres), np.arange(num_of_genres)] = -2 # I don't want to have this obvious correlations in the top-k correlations\n",
    "#-2 as I do not need negatively correlated variables anyway\n",
    "genres_sentiment_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(no genres listed)    0.116656\n",
       "Action                0.620187\n",
       "Adventure             0.620187\n",
       "Animation             0.746318\n",
       "Children              0.746318\n",
       "Comedy                0.637221\n",
       "Crime                 0.529792\n",
       "Documentary           0.348751\n",
       "Drama                 0.520476\n",
       "Fantasy               0.606182\n",
       "Film-Noir             0.348751\n",
       "Horror                0.419584\n",
       "IMAX                  0.392071\n",
       "Musical               0.537097\n",
       "Mystery               0.517156\n",
       "Romance               0.637221\n",
       "Sci-Fi                0.588742\n",
       "Thriller              0.607969\n",
       "War                   0.434633\n",
       "Western               0.314351\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_sentiment_correlation.max() # the strongest correlations are quite weak still."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adventure    0.620187\n",
       "Thriller     0.607969\n",
       "Sci-Fi       0.588742\n",
       "Comedy       0.499832\n",
       "Name: Action, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets select only best 4 correlations\n",
    "best_correlations = {}\n",
    "for i, (genre_name, correlations) in enumerate(genres_sentiment_correlation.iteritems()):\n",
    "    best_correlations[genre_name] = correlations.sort_values(ascending=False)[:4]\n",
    "\n",
    "best_correlations[\"Action\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last thing could be to select best films from given genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_films_in_genre = defaultdict(lambda : [])\n",
    "\n",
    "for movieId, positive_ratings in useful_ratings.groupby(\"movieId\").rating.sum().iteritems():\n",
    "    name, genres = movies_mapping_genre[movieId]\n",
    "    for genre in genres:\n",
    "        best_films_in_genre[genre].append((name, positive_ratings))\n",
    "\n",
    "for genre, films in best_films_in_genre.items():\n",
    "    best_films_in_genre[genre] = sorted(films, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Forrest Gump (1994)', 236),\n",
       " ('American Beauty (1999)', 173),\n",
       " ('Princess Bride, The (1987)', 124),\n",
       " ('Good Will Hunting (1997)', 119),\n",
       " ('Shrek (2001)', 102)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_films_in_genre[\"Romance\"][:5] #not sure why forrest gump and shrek are romances but fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>356</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "      <td>Comedy|Drama|Romance|War</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieId                title                    genres\n",
       "321      356  Forrest Gump (1994)  Comedy|Drama|Romance|War"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_genre[movies_genre.title=='Forrest Gump (1994)'] # So for sure so more restrictive genres mapping would be nice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So this is the end of the analysis and now let's move to the actual implementation\n",
    "Think recommender will think in a hierarchical approach:\n",
    "\n",
    "* First it looks in the assosiactions rules concerning concrete films (This will be build iteratively starting from low support and low rule length ending in bigger support and a little bit longer rules). However the length of the frequent sets will be at most 4/5.\n",
    "* If it doesn't find anything there. Then it moves to the rules about genres, build in the same way. \n",
    "* If still no results we utilize the correlation matrix to find which genre would be good\n",
    "* If we have a genre we will just try to reccomend not viewed movies starting from the best\\worst ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from itertools import chain, combinations\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilmTransformer:\n",
    "    \"\"\"This class performs necessary transformation to the dataset\n",
    "    \"\"\"\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "\n",
    "    def binarize_ratings(self, ratings, negative_bound=2, positive_bound=4):\n",
    "        \"\"\"Instead of rating on numerical scale we obtain either 1 (positive) or -1 (negative) ratings\n",
    "\n",
    "        Args:\n",
    "            ratings (_type_): _description_\n",
    "            negative_bound (int, optional): Which is biggest score for negative. Defaults to 2.\n",
    "            positive_bound (int, optional): What is smaller score for positive. Defaults to 4.\n",
    "\n",
    "        Returns:\n",
    "            _type_: binarized DataFrame\n",
    "        \"\"\"\n",
    "        mask_with_useful_ratings = (ratings.rating >=positive_bound)  | (ratings.rating <= negative_bound)\n",
    "\n",
    "        useful_ratings = ratings.copy().loc[mask_with_useful_ratings,:]\n",
    "        \n",
    "        useful_ratings[\"rating\"] = useful_ratings.rating.apply(lambda x: 1 if x >= 4 else -1)\n",
    "\n",
    "        return useful_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilmDataset:\n",
    "    \"\"\"Object storing all the information concerning the Films\n",
    "    \"\"\"\n",
    "    def __init__(self, movies_path, ratings_path):\n",
    "        self.transformer = FilmTransformer()\n",
    "\n",
    "        self.movies_path = movies_path\n",
    "        self.ratings_path = ratings_path\n",
    "\n",
    "        self.movies = pd.read_csv(os.path.join(data_folder, \"movies.csv\"))\n",
    "        self.ratings = pd.read_csv(os.path.join(data_folder, \"ratings.csv\")).drop(\"timestamp\", axis=1)\n",
    "\n",
    "        self.ratings = self.transformer.binarize_ratings(self.ratings)\n",
    "\n",
    "        self.ratings_positive = self.ratings[self.ratings.rating == 1]\n",
    "        self.ratings_negative = self.ratings[self.ratings.rating == -1]\n",
    "\n",
    "    def get_positive_transactions(self, users_id):\n",
    "        return [\n",
    "            list(self.ratings_positive[self.ratings_positive.userId == x].movieId)\n",
    "            for x in users_id\n",
    "        ]\n",
    "    \n",
    "    def get_negative_transactions(self, users_id):\n",
    "        return [\n",
    "            list(self.ratings_negative[self.ratings_negative.userId == x].movieId)\n",
    "            for x in users_id\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilmMetadata():\n",
    "    \"\"\"Class containing all meta information about films (should be split into 2 classes probably). \n",
    "       All needed mappings, users that gave positive rating\n",
    "       also ranking films from all genres sorted w.r.t most positively reviewed\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset : FilmDataset):\n",
    "        self.dataset = dataset\n",
    "        self.update_movies_mapping()\n",
    "        self.update_best_worst_films()\n",
    "\n",
    "        self.users_positive =self.dataset.ratings_positive.userId.unique()\n",
    "        self.num_of_positive_users = self.users_positive.size\n",
    "\n",
    "        self.users_negative =self.dataset.ratings_negative.userId.unique()\n",
    "        self.num_of_negative_users = self.users_negative.size    \n",
    "\n",
    "    def update_movies_mapping(self):\n",
    "        self.id_to_movie_mapping = {} # at each id we have a movie title and genres\n",
    "        self.movie_to_id_mapping = {} #mapping in other direction also is needed\n",
    "        self.all_genres = set() #all genres that exists\n",
    "\n",
    "        for index, row in self.dataset.movies.iterrows():\n",
    "            self.id_to_movie_mapping[row.movieId] = {}\n",
    "            self.id_to_movie_mapping[row.movieId][\"title\"] = row.title\n",
    "            self.movie_to_id_mapping[row.title] = row.movieId\n",
    "\n",
    "            movie_genres = row.genres.split(\"|\")\n",
    "            self.id_to_movie_mapping[row.movieId][\"genres\"] = movie_genres\n",
    "\n",
    "            self.all_genres = self.all_genres.union(set(movie_genres))\n",
    "            \n",
    "        self.num_of_genres = len(self.all_genres)\n",
    "\n",
    "    def update_best_worst_films(self,):\n",
    "        self.best_films_in_genre = defaultdict(lambda : [])\n",
    "        self.worst_films_in_genre = defaultdict(lambda : []) #worst films are just best reversed\n",
    "\n",
    "        for movieId, positive_ratings in self.dataset.ratings.groupby(\"movieId\").rating.sum().iteritems():\n",
    "            name, genres = self.id_to_movie_mapping[movieId].values()\n",
    "            for genre in genres:\n",
    "                self.best_films_in_genre[genre].append((name, positive_ratings))\n",
    "\n",
    "        for genre, films in self.best_films_in_genre.items():\n",
    "            self.best_films_in_genre[genre] = sorted(films, key = lambda x: x[1], reverse=True)\n",
    "            self.worst_films_in_genre[genre] = self.best_films_in_genre[genre][::-1]\n",
    "\n",
    "    #Some mapping functions\n",
    "    def numbers_to_movies(self, numbers):\n",
    "        return [self.id_to_movie_mapping[num][\"title\"] for num in numbers]\n",
    "\n",
    "    def movies_to_numbers(self, movies):\n",
    "        return [self.movie_to_id_mapping[title] for title in movies]\n",
    "\n",
    "    def get_movies_genre(self, movie_id):\n",
    "        return self.id_to_movie_mapping[movie_id][\"genres\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreDataset():\n",
    "    \"\"\"Class containing the Genre data\n",
    "    \"\"\"\n",
    "    def __init__(self, film_dataset: FilmDataset, metadata: FilmMetadata):\n",
    "        self.metadata = metadata\n",
    "        self.film_dataset = film_dataset\n",
    "        \n",
    "        self.all_genres_list_sorted = sorted(list(self.metadata.all_genres)) # to has always the same mapping\n",
    "        self.mapping_genre_to_numbers = {v:k for k,v in zip(range(len(self.metadata.all_genres)), self.all_genres_list_sorted)}\n",
    "        self.mapping_numbers_to_genre = {v:k for k,v in self.mapping_genre_to_numbers.items()}\n",
    " \n",
    "        user_genres = defaultdict(lambda : [0] * self.metadata.num_of_genres)\n",
    "\n",
    "        #So here based on film data we prepare genre data\n",
    "        for index, row in self.film_dataset.ratings.iterrows():\n",
    "            userId, movieId, rating = row\n",
    "            for genre in self.metadata.id_to_movie_mapping[movieId][\"genres\"]:\n",
    "                user_genres[userId][self.mapping_genre_to_numbers[genre]] += rating\n",
    "\n",
    "        self.genres_sentiment = pd.DataFrame(user_genres).transpose()\n",
    "        self.genres_sentiment.columns = self.all_genres_list_sorted\n",
    "\n",
    "        self.genres_sentiment = self.genres_sentiment.apply(lambda x: np.sign(x))\n",
    "\n",
    "    def get_positive_transactions(self, users_id):\n",
    "        positive_transactions_genre = []\n",
    "        #I should vectorize it\n",
    "        for userId in users_id:\n",
    "            liked_genres = np.argwhere((self.genres_sentiment.loc[userId] == 1).to_numpy())\n",
    "            positive_transactions_genre.append(list(liked_genres.flatten()))\n",
    "\n",
    "        return positive_transactions_genre\n",
    "\n",
    "    def get_negative_transactions(self, users_id):\n",
    "        negative_transactions_genre = []\n",
    "        for userId in users_id:\n",
    "            not_liked_genres = np.argwhere((self.genres_sentiment.loc[userId] == -1).to_numpy())\n",
    "            negative_transactions_genre.append(list(not_liked_genres.flatten()))\n",
    "\n",
    "        return negative_transactions_genre\n",
    "\n",
    "    def numbers_to_genres(self, numbers):\n",
    "        return [self.mapping_numbers_to_genre[num] for num in numbers]\n",
    "\n",
    "    def genres_to_numbers(self, genres):\n",
    "        return [self.mapping_genre_to_numbers[g] for g in genres]\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rules:\n",
    "    \"\"\"Class containing all the association rules\n",
    "       It shouldn't cover positive and negative in the same time but instead we should have two instances of the same class.\n",
    "        Not the best code, sorry for that\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset : FilmDataset, metadata: FilmMetadata, metric=\"lift\", min_threshold=5, min_supports_pos=[0.01, 0.02, 0.03], min_supports_neg=[0.01,0.02,0.03]):\n",
    "        self.te_positive = TransactionEncoder()\n",
    "        self.te_negative = TransactionEncoder()\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.metadata = metadata\n",
    "\n",
    "        te_array = self.te_positive.fit_transform(self.dataset.get_positive_transactions(self.metadata.users_positive))\n",
    "        self.df_positive = pd.DataFrame(te_array, columns=self.te_positive.columns_)\n",
    "        self.te_positive_id_to_filmId = {v:k for k,v in self.te_positive.columns_mapping_.items()}\n",
    "\n",
    "        te_array = self.te_negative.fit_transform(self.dataset.get_negative_transactions(self.metadata.users_negative))\n",
    "        self.df_negative = pd.DataFrame(te_array, columns=self.te_negative.columns_)\n",
    "        self.te_negative_id_to_filmId = {v:k for k,v in self.te_negative.columns_mapping_.items()}\n",
    "\n",
    "        self.metric = metric\n",
    "        self.min_threshold = min_threshold\n",
    "        self.min_supports_pos = min_supports_pos\n",
    "        self.min_supports_neg = min_supports_neg\n",
    "    \n",
    "    def fit(self,):\n",
    "        self.positive_rules = self.fit_procedure(self.df_positive, self.min_supports_pos)\n",
    "        self.negative_rules = self.fit_procedure(self.df_negative, self.min_supports_neg)\n",
    "\n",
    "    def fit_procedure(self, df, min_supports):\n",
    "        max_lengths = [2,3,4]\n",
    "\n",
    "        #To make this fast I assume that we can choose any film B having X as antecedent. \n",
    "        # So we can just store all the consequents for given antecedent in a dictonary\n",
    "        #And for different antecedents length Ill have separate dictonaries\n",
    "        #and then during inference we can just do a quick lookup\n",
    "        num_of_antecedents = [1,2,3]\n",
    "        rules_with_n_antecedents = {antecedents:defaultdict(lambda : set()) for antecedents in num_of_antecedents}\n",
    "        \n",
    "        for i, (min_supp, max_length) in enumerate(zip(min_supports, max_lengths)):\n",
    "            frequent_itemsets = fpgrowth(df, min_support=min_supp, use_colnames=True, max_len=max_length)\n",
    "            rules = association_rules(frequent_itemsets, metric=self.metric, min_threshold=self.min_threshold)\n",
    "\n",
    "            if i > 0:\n",
    "                # I already have all rules with max_length - 1 so I am only interested in the shorter ones\n",
    "                shorter_rules_filter = rules.apply(lambda x: len(x.antecedents.union(x.consequents)), axis=1) > max_lengths[i-1]\n",
    "                rules = rules[shorter_rules_filter]\n",
    "\n",
    "            #Here I update all previously gathered rules of each length by new consequents\n",
    "            for id, rule in rules.iterrows():\n",
    "                antecedents = tuple(sorted(list(rule.antecedents)))\n",
    "                consequents = rule.consequents\n",
    "\n",
    "                for ant_len in num_of_antecedents[:i+1]:\n",
    "                    if len(antecedents) == ant_len:\n",
    "                        rules_with_n_antecedents[ant_len][antecedents] = rules_with_n_antecedents[ant_len][antecedents].union(consequents)\n",
    "\n",
    "        return rules_with_n_antecedents\n",
    "    \n",
    "    def get_all_possible_consequents(self, antecedents: tuple, rules):\n",
    "        \"\"\"Here we tru to get all possible consequents and if e.g someone gave 4 films. Then if we do not suceed with all 4 films\n",
    "        We look if some subset of these 4 films have a consequent\n",
    "        \"\"\"\n",
    "        antecedents = tuple(sorted(antecedents))\n",
    "        if len(antecedents) in rules and antecedents in rules[len(antecedents)]:\n",
    "            yield rules[len(antecedents)][antecedents]\n",
    "\n",
    "        all_subsets = chain.from_iterable(combinations(antecedents, r) for r in range(1, min(4, len(antecedents)+1))) # from smallest to biggest\n",
    "        all_subsets_from_biggest = sorted(list(all_subsets), key = lambda x: len(x), reverse=True)\n",
    "        for smaller_antecedents in all_subsets_from_biggest:\n",
    "            if smaller_antecedents in rules[len(smaller_antecedents)]:\n",
    "                yield rules[len(smaller_antecedents)][smaller_antecedents]\n",
    "\n",
    "\n",
    "    def transform(self, antecedents, positive=True,):\n",
    "        #Now after few days I see it is not well written...\n",
    "        rules = self.positive_rules if positive else self.negative_rules\n",
    "        te = self.te_positive if positive else self.te_negative\n",
    "        mapping = self.te_positive_id_to_filmId if positive else self.te_negative_id_to_filmId\n",
    "\n",
    "        antecedents = [te.columns_mapping_[a] for a in antecedents] # we must come back to the mapping created by TE\n",
    "        for consequent in self.get_all_possible_consequents(antecedents, rules):\n",
    "            if len(consequent) > 0:\n",
    "                return [mapping[c] for c in consequent]\n",
    "\n",
    "        return []\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelationRule:\n",
    "    \"\"\"Separate class applying the best correlation rule\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset: GenreDataset, metadata: FilmMetadata):\n",
    "        self.dataset = dataset\n",
    "        self.metadata = metadata\n",
    "\n",
    "        self.genres_sentiment_correlation = self.dataset.genres_sentiment.corr()\n",
    "        self.genres_sentiment_correlation.values[np.arange(self.metadata.num_of_genres), np.arange(self.metadata.num_of_genres)] = -2\n",
    "\n",
    "        self.best_correlations = {}\n",
    "        for i, (genre_name, correlations) in enumerate(self.genres_sentiment_correlation.iteritems()):\n",
    "            self.best_correlations[genre_name] = correlations.sort_values(ascending=False)[:4]\n",
    "\n",
    "    def transform(self, genre):\n",
    "        #during selecting genre each has weight proportional to the correlation value\n",
    "        genre_names = self.best_correlations[genre].index\n",
    "        weights = self.best_correlations[genre].values\n",
    "        weights /= np.sum(weights)\n",
    "        \n",
    "        genre_num = np.random.choice(np.arange(len(weights)), size=1, p=weights)\n",
    "\n",
    "        selected_genre = genre_names[genre_num].values[0]\n",
    "\n",
    "        return selected_genre\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    \"\"\"The final class using all the previously written modules\n",
    "    \"\"\"\n",
    "    def __init__(self, rules_film: Rules, rules_genre : Rules, correlation_rules: CorrelationRule, metadata : FilmMetadata, genre_dataset: GenreDataset):\n",
    "        self.rules_film = rules_film\n",
    "        self.rules_genre = rules_genre\n",
    "        self.correlation_rules = correlation_rules\n",
    "\n",
    "        self.metadata = metadata\n",
    "        self.genre_dataset = genre_dataset\n",
    "\n",
    "    def select_film(self, selected_genre, previously_watched, positive):\n",
    "        \"\"\"Given the selected genre this function try to suggest best or worst films\n",
    "           and it stops when it find a film not previously_watched by the user\n",
    "        \"\"\"\n",
    "        films_to_choose_from = self.metadata.best_films_in_genre if positive else self.metadata.worst_films_in_genre\n",
    "        for film in films_to_choose_from[selected_genre]:\n",
    "            name, positive_score = film\n",
    "            if name not in previously_watched:\n",
    "                return name\n",
    "\n",
    "    def remove_watched(self, selected, previously_watched):\n",
    "        return [s for s in selected if s not in previously_watched]    \n",
    "\n",
    "    def recommend(self, antecedents, previously_watched, positive=True):\n",
    "        \"\"\"This function basically try to use all the rules until one of them suceed\n",
    "        \"\"\"\n",
    "        antecedents = tuple(self.metadata.movies_to_numbers(antecedents))\n",
    "        \n",
    "\n",
    "        films = self.rules_film.transform(antecedents, positive)\n",
    "        films = self.metadata.numbers_to_movies(films)\n",
    "        films_filtered = self.remove_watched(films, previously_watched)\n",
    "        \n",
    "        if films_filtered:\n",
    "            return films_filtered\n",
    "        \n",
    "        for a in antecedents:\n",
    "            antecedent_genres = self.genre_dataset.genres_to_numbers(self.metadata.get_movies_genre(a))\n",
    "            genres = self.rules_genre.transform(tuple(antecedent_genres), positive)\n",
    "            if genres:\n",
    "                genres = self.genre_dataset.numbers_to_genres(genres)\n",
    "                selected_genre = np.random.choice(genres)\n",
    "                \n",
    "                return self.select_film(selected_genre, previously_watched, positive)\n",
    "                    \n",
    "        for a in antecedents:\n",
    "            for genre in self.metadata.get_movies_genre(a):\n",
    "                selected_genre = self.correlation_rules.transform(genre)\n",
    "                return self.select_film(selected_genre, previously_watched, positive)\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have all the classes we just need to initialize every object. We could do this every day as our database of films increase.\n",
    "`This code runs for about 2 minutes. But after that everything is stored in dictonaries so inference is just a simple lookup.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "movies_path = os.path.join(data_folder, \"movies.csv\")\n",
    "ratings_path = os.path.join(data_folder, \"ratings.csv\")\n",
    "\n",
    "film_dataset = FilmDataset(movies_path, ratings_path)\n",
    "metadata = FilmMetadata(film_dataset)\n",
    "\n",
    "genre_dataset = GenreDataset(film_dataset, metadata)\n",
    "\n",
    "rules_film = Rules(film_dataset, metadata, min_threshold=7)\n",
    "rules_film.fit()\n",
    "\n",
    "rules_genre = Rules(genre_dataset, metadata, min_threshold = 1.25, min_supports_pos=[0.4, 0.5, 0.6], min_supports_neg=[0.05,0.1,0.15])\n",
    "rules_genre.fit()\n",
    "\n",
    "correlation_rules = CorrelationRule(genre_dataset, metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = Recommender(rules_film, rules_genre, correlation_rules, metadata, genre_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Silence of the Lambs, The (1991)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I liked films Pulp Fiction and Reservoir Dogs what to watch next?\n",
    "recommender.recommend({\"Pulp Fiction (1994)\", \"Reservoir Dogs (1992)\"}, set([\"Pulp Fiction (1994)\", \"Reservoir Dogs (1992)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['French Kiss (1995)']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I didn't like the mask what not to watch next? \n",
    "recommender.recommend({\"Mask, The (1994)\"}, set(\"Mask, The (1994)\"), positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pallbearer, The (1996)',\n",
       " 'First Wives Club, The (1996)',\n",
       " 'Ransom (1996)',\n",
       " 'Crow: City of Angels, The (1996)',\n",
       " 'Dragonheart (1996)',\n",
       " 'Powder (1995)',\n",
       " 'Bad Company (1995)',\n",
       " 'Tie That Binds, The (1995)']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I've watched and liked Grumpier Old Men - what to watch next?\n",
    "recommender.recommend({'Grumpier Old Men (1995)'}, set('Grumpier Old Men (1995)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pallbearer, The (1996)',\n",
       " 'First Wives Club, The (1996)',\n",
       " 'Ransom (1996)',\n",
       " 'Crow: City of Angels, The (1996)',\n",
       " 'Dragonheart (1996)',\n",
       " 'Powder (1995)',\n",
       " 'Tie That Binds, The (1995)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I've watched, bad company  too from these, so it would not be included\n",
    "recommender.recommend({'Grumpier Old Men (1995)', 'Bad Company (1995)'}, set(['Grumpier Old Men (1995)', 'Bad Company (1995)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forrest Gump (1994)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I've watched, all from that list but I liked only these two\n",
    "recommender.recommend({'Grumpier Old Men (1995)', 'Bad Company (1995)'}, \n",
    "set(['Grumpier Old Men (1995)', 'Bad Company (1995)','Pallbearer, The (1996)',\n",
    " 'First Wives Club, The (1996)',\n",
    " 'Ransom (1996)',\n",
    " 'Crow: City of Angels, The (1996)',\n",
    " 'Dragonheart (1996)',\n",
    " 'Powder (1995)',\n",
    " 'Tie That Binds, The (1995)'\n",
    " ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hollow Man (2000)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I've watched star Wars But I didn't like it, what shouldn't I watch?\n",
    "recommender.recommend({'Star Wars: Episode IV - A New Hope (1977)'}, \n",
    "set(['Grumpier Old Men (1995)', 'Bad Company (1995)','Pallbearer, The (1996)',\n",
    " 'First Wives Club, The (1996)',\n",
    " 'Ransom (1996)',\n",
    " 'Crow: City of Angels, The (1996)',\n",
    " 'Dragonheart (1996)',\n",
    " 'Powder (1995)',\n",
    " 'Tie That Binds, The (1995)',\n",
    " 'Star Wars: Episode IV - A New Hope (1977)'\n",
    " ]), positive=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a2214deb2e00a4588fb64d6e2ad9e78ab07788ce628f39696990503e7a4b014"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
